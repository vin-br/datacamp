{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python\n",
    "\n",
    "## Introduction to Deep Learning in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fine-tuning keras models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing optimization parameters\n",
    "\n",
    "- Import SGD from tensorflow.keras.optimizers.\n",
    "- Create a list of learning rates to try optimizing with called lr_to_test. The learning rates in it should be .000001, 0.01, and 1.\n",
    "- Using a for loop to iterate over lr_to_test:\n",
    "    - Use the get_new_model() function to build a new, unoptimized model.\n",
    "    - Create an optimizer called my_optimizer using the SGD() constructor with keyword argument lr=lr.\n",
    "    - Compile your model. Set the optimizer parameter to be the SGD object you created above, and because this is a classification problem, use 'categorical_crossentropy' for the loss parameter.\n",
    "    - Fit your model using the predictors and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SGD optimizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print(\"\\n\\nTesting model with learning rate: %f\\n\" % lr)\n",
    "\n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "\n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer, loss=\"categorical_crossentropy\")\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(predictors, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating model accuracy on validation dataset\n",
    "\n",
    "- Compile your model using 'adam' as the optimizer and 'categorical_crossentropy' for the loss. To see what fraction of predictions are correct (the accuracy) in each epoch, specify the additional keyword argument metrics=['accuracy'] in model.compile().\n",
    "- Fit the model using the predictors and target. Create a validation split of 30% (or 0.3). This will be reported in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation=\"relu\", input_shape=input_shape))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors, target, validation_split=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early stopping: Optimizing the optimization\n",
    "\n",
    "- Import EarlyStopping from tensorflow.keras.callbacks.\n",
    "- Compile the model, once again using 'adam' as the optimizer, 'categorical_crossentropy' as the loss function, and metrics=['accuracy'] to see the accuracy at each epoch.\n",
    "- Create an EarlyStopping object called early_stopping_monitor. Stop optimization when the validation loss hasn't improved for 2 epochs by specifying the patience parameter of EarlyStopping() to be 2.\n",
    "- Fit the model using the predictors and target. Specify the number of epochs to be 30 and use a validation split of 0.3. In addition, pass [early_stopping_monitor] to the callbacks parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EarlyStopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation=\"relu\", input_shape=input_shape))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, epochs=30, validation_split=0.3, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with wider networks\n",
    "\n",
    "- Create model_2 to replicate model_1, but use 100 nodes instead of 10 for the first two Dense layers you add with the 'relu' activation. Use 2 nodes for the Dense output layer with 'softmax' as the activation.\n",
    "- Compile model_2 as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy'].\n",
    "- Hit 'Submit Answer' to fit both the models and visualize which one gives better results! Notice the keyword argument verbose=False in model.fit(): This prints out fewer updates, since you'll be evaluating the models graphically instead of through text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation=\"relu\", input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(\n",
    "    predictors,\n",
    "    target,\n",
    "    epochs=15,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping_monitor],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(\n",
    "    predictors,\n",
    "    target,\n",
    "    epochs=15,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping_monitor],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history[\"val_loss\"], \"r\", model_2_training.history[\"val_loss\"], \"b\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation score\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding layers to a network\n",
    "\n",
    "- Specify a model called model_2 that is like model_1, but which has 3 hidden layers of 10 units instead of only 1 hidden layer.\n",
    "    - Use input_shape to specify the input shape in the first hidden layer.\n",
    "    - Use 'relu' activation for the 3 hidden layers and 'softmax' for the output layer, which should have 2 units.\n",
    "- Compile model_2 as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy'].\n",
    "- Hit 'Submit Answer' to fit both the models and visualize which one gives better results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(10, activation=\"relu\", input_shape=input_shape))\n",
    "model_2.add(Dense(10, activation=\"relu\"))\n",
    "model_2.add(Dense(10, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.4, verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.4, verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history[\"val_loss\"], \"r\", model_2_training.history[\"val_loss\"], \"b\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation score\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building your own digit recognition model\n",
    "\n",
    "- Create a Sequential object to start your model. Call this model.\n",
    "- Add the first Dense hidden layer of 50 units to your model with 'relu' activation. For this data, the input_shape is (784,).\n",
    "- Add a second Dense hidden layer with 50 units and a 'relu' activation function.\n",
    "- Add the output layer. Your activation function should be 'softmax', and the number of nodes in this layer should be the same as the number of possible outputs in this case: 10.\n",
    "- Compile model as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy'].\n",
    "- Fit the model using X and y using a validation_split of 0.3 and 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(50, activation=\"relu\", input_shape=(784,)))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, epochs=10, validation_split=0.3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

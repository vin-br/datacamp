{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python\n",
    "\n",
    "## Image Processing with Keras in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Convolutions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One dimensional convolutions\n",
    "\n",
    "Multiply each window in the input array with the kernel and sum the multiplied result and allocate the result into the correct entry in the output array (conv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "kernel = np.array([1, -1, 0])\n",
    "conv = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "# Output array\n",
    "for ii in range(8):\n",
    "    conv[ii] = (kernel * array[ii:ii+3]).sum()\n",
    "\n",
    "# Print conv\n",
    "print(conv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image convolutions\n",
    "\n",
    "- Select the right window from the image in each iteration and multiply this part of the image with the kernel.\n",
    "- Sum the result and allocate the sum to the correct entry in the output array (results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\n",
    "result = np.zeros(im.shape)\n",
    "\n",
    "# Output array\n",
    "for ii in range(im.shape[0] - 3):\n",
    "    for jj in range(im.shape[1] - 3):\n",
    "        result[ii, jj] = (im[ii:ii+3, jj:jj+3] * kernel).sum()\n",
    "\n",
    "# Print result\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining image convolution kernels\n",
    "\n",
    "Define a kernel that finds horizontal lines in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[-1, -1, -1], \n",
    "                   [1, 1, 1],\n",
    "                   [-1, -1 ,-1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a kernel that finds a light spot surrounded by dark pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[-1, -1, -1], \n",
    "                   [-1, 1, -1],\n",
    "                   [-1, -1, -1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a kernel that finds a dark spot surrounded by bright pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[1, 1, 1], \n",
    "                   [1, -1, 1],\n",
    "                   [1, 1, 1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional network for image classification\n",
    "\n",
    "- Add a Conv2D layer to construct the input layer of the network. Use a kernel size of 3 by 3. You can use the img_rows and img_cols objects available in your workspace to define the input_shape of this layer.\n",
    "- Add a Flatten layer to translate between the image processing and classification part of your network.\n",
    "- Add a Dense layer to classify the 3 different categories of clothing in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary components from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "# Initialize the model object\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(10, kernel_size=3, activation=\"relu\", input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Flatten the output of the convolutional layer\n",
    "model.add(Flatten())\n",
    "# Add an output layer for the 3 categories\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a CNN to classify clothing types\n",
    "\n",
    "- Compile the network using the 'adam' optimizer and the 'categorical_crossentropy' cost function. In the metrics list define that the network to report 'accuracy'.\n",
    "- Fit the network on train_data and train_labels. Train for 3 epochs with a batch size of 10 images. In training, set aside 20% of the data as a validation set, using the validation_split keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model on a training set\n",
    "model.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating a CNN with test data\n",
    "\n",
    "- Evaluate the data on a separate test set: test_data and test_labels.\n",
    "- Use the same batch size that was used for fitting (10 images per batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on separate test data\n",
    "model.evaluate(test_data, test_labels, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add padding to a CNN\n",
    "\n",
    "Add a Conv2D layer and choose a padding such that the output has the same size as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional layer\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        10, kernel_size=3, activation=\"relu\", input_shape=(img_rows, img_cols, 1), padding=\"same\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feed into output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add strides to a convolutional network\n",
    "\n",
    "Construct a neural network with a Conv2D layer with strided convolutions that skips every other pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional layer\n",
    "model.add(\n",
    "    Conv2D(10, kernel_size=3, activation=\"relu\", input_shape=(img_rows, img_cols, 1), strides=2)\n",
    ")\n",
    "\n",
    "# Feed into output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0 (main, Jan  2 2023, 14:17:44) [Clang 12.0.0 (clang-1200.0.32.29)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4053dca0899ea429c38048b3b4c554b4290776a3cdcda77797b988a5de7bd87b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

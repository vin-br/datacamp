{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python\n",
    "\n",
    "## Image Processing with Keras in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Going Deeper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a deep learning network\n",
    "\n",
    "- The first convolutional layer is the input layer of the network. This should have 15 units with kernels of 2 by 2 pixels. It should have a 'relu' activation function. It can use the variables img_rows and img_cols to define its input_shape.\n",
    "- The second convolutional layer receives its inputs from the first layer. It should have 5 units with kernels of 2 by 2 pixels. It should also have a 'relu' activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer (15 units)\n",
    "model.add(Conv2D(15, kernel_size=2, activation=\"relu\", input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "\n",
    "# Add another convolutional layer (5 units)\n",
    "model.add(Conv2D(5, kernel_size=2, activation=\"relu\"))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a deep CNN to classify clothing images\n",
    "\n",
    "- Compile the model to use the categorical cross-entropy loss function and the Adam optimizer.\n",
    "- Train the network with train_data for 3 epochs with batches of 10 images each.\n",
    "- Use randomly selected 20% of the training data as validation data during training.\n",
    "- Evaluate the model with test_data, use a batch size of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model to training data\n",
    "model.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "model.evaluate(test_data, test_labels, batch_size=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many parameters in a deep CNN?\n",
    "\n",
    "Summarize the network, providing a count of the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(10, kernel_size=2, activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(10, kernel_size=2, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your own pooling operation\n",
    "\n",
    "\n",
    "- Index into the input array (im) and select the right window.\n",
    "- Find the maximum in this window.\n",
    "- Allocate this into the right entry in the output array (result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result placeholder\n",
    "result = np.zeros((im.shape[0] // 2, im.shape[1] // 2))\n",
    "\n",
    "# Pooling operation\n",
    "for ii in range(result.shape[0]):\n",
    "    for jj in range(result.shape[1]):\n",
    "        result[ii, jj] = np.max(im[ii * 2 : ii * 2 + 2, jj * 2 : jj * 2 + 2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras pooling layers\n",
    "\n",
    "- Add an input convolutional layer (15 units, kernel size of 2, relu activation).\n",
    "- Add a maximum pooling operation (pooling over windows of size 2x2).\n",
    "- Add another convolution layer (5 units, kernel size of 2, relu activation).\n",
    "- Flatten the output of the second convolution and add a Dense layer for output (3 categories, softmax activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation=\"relu\", input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a pooling operation\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation=\"relu\"))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a deep CNN with pooling to classify images\n",
    "\n",
    "- Compile this model to use the categorical cross-entropy loss function and the Adam optimizer.\n",
    "- Train the model for 3 epochs with batches of size 10.\n",
    "- Use 20% of the data as validation data.\n",
    "- Evaluate the model on test_data with test_labels (also batches of size 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit to training data\n",
    "model.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10)\n",
    "\n",
    "# Evaluate on test data\n",
    "model.evaluate(test_data, test_labels, batch_size=10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

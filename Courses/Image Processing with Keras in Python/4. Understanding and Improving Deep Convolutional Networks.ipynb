{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python\n",
    "\n",
    "## Image Processing with Keras in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Understanding and Improving Deep Convolutional Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves\n",
    "\n",
    "\n",
    "- Fit the model to the training data (train_data).\n",
    "- Use a validation split of 20%, 3 epochs and batch size of 10.\n",
    "- Plot the training loss.\n",
    "- Plot the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and store the training object\n",
    "training = model.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10)\n",
    "\n",
    "# Extract the history from the training object\n",
    "history = training.history\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(history[\"loss\"])\n",
    "# Plot the validation loss\n",
    "plt.plot(history[\"val_loss\"])\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using stored weights to predict in a test set\n",
    "\n",
    "- Load the weights from a file called 'weights.hdf5'.\n",
    "- Predict the classes of the first three images from test_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights from file\n",
    "model.load_weights(\"weights.hdf5\")\n",
    "\n",
    "# Predict from the first three images in the test data\n",
    "model.predict(test_data[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding dropout to your network\n",
    "\n",
    "- Add dropout applied to the first layer with 20%.\n",
    "- Add a flattening layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation=\"relu\", input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a dropout layer\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation=\"relu\"))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add batch normalization to your network\n",
    "\n",
    "- Add the first convolutional layer. You can use the img_rows and img_cols objects available in your workspace to define the input_shape of this layer.\n",
    "- Add batch normalization applied to the outputs of the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation=\"relu\", input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "\n",
    "# Add batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation=\"relu\"))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

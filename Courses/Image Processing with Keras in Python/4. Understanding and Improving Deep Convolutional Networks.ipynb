{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python\n",
    "\n",
    "## Image Processing with Keras in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Understanding and Improving Deep Convolutional Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves\n",
    "\n",
    "\n",
    "- Fit the model to the training data (train_data).\n",
    "- Use a validation split of 20%, 3 epochs and batch size of 10.\n",
    "- Plot the training loss.\n",
    "- Plot the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and store the training object\n",
    "training = model.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10)\n",
    "\n",
    "# Extract the history from the training object\n",
    "history = training.history\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(history[\"loss\"])\n",
    "# Plot the validation loss\n",
    "plt.plot(history[\"val_loss\"])\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using stored weights to predict in a test set\n",
    "\n",
    "- Load the weights from a file called 'weights.hdf5'.\n",
    "- Predict the classes of the first three images from test_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights from file\n",
    "model.load_weights(\"weights.hdf5\")\n",
    "\n",
    "# Predict from the first three images in the test data\n",
    "model.predict(test_data[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding dropout to your network\n",
    "\n",
    "- Add dropout applied to the first layer with 20%.\n",
    "- Add a flattening layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation=\"relu\", input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a dropout layer\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation=\"relu\"))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add batch normalization to your network\n",
    "\n",
    "- Add the first convolutional layer. You can use the img_rows and img_cols objects available in your workspace to define the input_shape of this layer.\n",
    "- Add batch normalization applied to the outputs of the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation=\"relu\", input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation=\"relu\"))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting a kernel from a trained network\n",
    "\n",
    "- Load the weights into the model from the file weights.hdf5.\n",
    "- Get the first convolutional layer in the model from the layers attribute.\n",
    "- Use the .get_weights() method to extract the weights from this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights into the model\n",
    "model.load_weights(\"weights.hdf5\")\n",
    "\n",
    "# Get the first convolutional layer from the model\n",
    "c1 = model.layers[0]\n",
    "\n",
    "# Get the weights of the first convolutional layer\n",
    "weights1 = c1.get_weights()\n",
    "\n",
    "# Pull out the first channel of the first kernel in the first layer\n",
    "kernel = weights1[0][..., 0, 0]\n",
    "print(kernel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing kernel responses\n",
    "\n",
    "- Use the convolution() function to convolve the extracted kernel with the first channel of the fourth item in the image array.\n",
    "- Visualize the resulting convolution with imshow()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convolve with the fourth image in test_data\n",
    "out = convolution(test_data[3, :, :, 0], kernel)\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(out)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
